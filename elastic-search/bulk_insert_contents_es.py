from elasticsearch import Elasticsearch, helpers
from faker import Faker
import random
from datetime import datetime, timedelta
import base64

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
ES_HOST = "http://localhost:9200"
INDEX_NAME = "contents"
TOTAL_DOCS = 1000000   # ìƒì„±í•  ì „ì²´ ë°ì´í„° ìˆ˜ (100ë§Œ ê±´)
BATCH_SIZE = 5000      # Bulk Insert ë°°ì¹˜ í¬ê¸°
TARGET_RATIO = 0.05    # íƒ€ê²Ÿ(ê²€ìƒ‰ í‚¤ì›Œë“œ í¬í•¨) ë°ì´í„° ë¹„ìœ¨ (5%)

# ES í´ë¼ì´ì–¸íŠ¸ ë° Faker ì´ˆê¸°í™”
es = Elasticsearch(ES_HOST)
fake = Faker()

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œ ëª©ë¡
KEYWORDS = ["Kafka", "Spring Boot", "Redis", "MSA", "Docker", "AWS", "Elasticsearch", "Kotlin"]

# ==========================================
# 2. ë°ì´í„° ìƒì„± ì œë„ˆë ˆì´í„°
# ==========================================
def generate_docs():
    print(f"ğŸš€ {TOTAL_DOCS}ê±´ ë°ì´í„° ìƒì„± ë° ì‚½ì… ì‹œì‘...")
    
    target_count = int(TOTAL_DOCS * TARGET_RATIO) 
    now = datetime.now()

    for i in range(TOTAL_DOCS):
        doc_id = i + 1
        is_target = i < target_count
        
        # [ìˆ˜ì •] ë‚ ì§œ ëœë¤í™” ë¡œì§ (íƒ€ê²Ÿ/ë…¸ì´ì¦ˆ ìƒê´€ì—†ì´ ì „ì²´ ê¸°ê°„ì— ê³ ë¥´ê²Œ ë¶„í¬)
        # 0ì¼ ~ 365ì¼ ì „ ì‚¬ì´ì˜ ëœë¤í•œ ë‚ ì§œ
        days_ago = random.randint(0, 365)
        
        # [ìˆ˜ì •] ì‹œê°„(ì‹œ/ë¶„/ì´ˆ) ëœë¤í™”
        # ê°™ì€ ë‚ ì§œë¼ë„ ì‹œê°„ì´ ë‹¤ë¥´ê²Œ í•˜ê¸° ìœ„í•´ 0 ~ 86400ì´ˆ(24ì‹œê°„) ì‚¬ì´ ëœë¤ ê°’ì„ ëºŒ
        random_seconds = random.randint(0, 86400)
        
        if is_target:
            # íƒ€ê²Ÿ ë°ì´í„°: í‚¤ì›Œë“œ í¬í•¨
            keyword = random.choice(KEYWORDS)
            title = f"{keyword} ê´€ë ¨ ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ {doc_id}"
            summary = f"ì´ ê¸€ì—ì„œëŠ” {keyword}ì™€ {random.choice(KEYWORDS)}ë¥¼ í™œìš©í•œ ì•„í‚¤í…ì²˜ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤."
        else:
            # ë…¸ì´ì¦ˆ ë°ì´í„°: ì¼ë°˜ í…ìŠ¤íŠ¸
            title = f"ì¼ìƒ ì´ì•¼ê¸° ë° ì—¬í–‰ í›„ê¸° {doc_id}"
            summary = fake.text(max_nb_chars=100)

        # ìµœì¢… ë‚ ì§œ ê³„ì‚° (í˜„ì¬ - ëœë¤ì¼ - ëœë¤ì´ˆ)
        pub_date = now - timedelta(days=days_ago, seconds=random_seconds)
        
        # [ì¤‘ìš”] Javaì˜ LocalDateTime í¬ë§·(yyyy-MM-ddTHH:mm:ss.SSS)ì— ë§ì¶˜ ë¬¸ìì—´ ë³€í™˜
        # %fëŠ” ë§ˆì´í¬ë¡œì´ˆ(6ìë¦¬)ì´ë¯€ë¡œ ë’¤ì— 3ìë¦¬ë¥¼ ì˜ë¼ì„œ ë°€ë¦¬ì´ˆ(3ìë¦¬)ë¡œ ë§ì¶¤
        pub_date_str = pub_date.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]

        # ê³ ìœ  ID ìƒì„± (URL ê¸°ë°˜ í•´ì‹œ)
        original_url = f"https://test.com/post/{doc_id}"
        unique_id_str = f"{random.randint(1,100)}-{original_url}"
        es_id = base64.b64encode(unique_id_str.encode('utf-8')).decode('utf-8')

        # ë¬¸ì„œ êµ¬ì¡° ìƒì„± (Java ì—”í‹°í‹°ì˜ @Field name ì†ì„±ê³¼ ì¼ì¹˜ì‹œí‚´ - Snake Case)
        doc = {
            "_index": INDEX_NAME,
            "_id": es_id,
            "_source": {
                "content_id": doc_id,
                "source_id": random.randint(1, 100),
                "source_name": "í…ŒìŠ¤íŠ¸ ë¸”ë¡œê·¸",
                "title": title,
                "summary": summary,
                "original_url": original_url,
                "thumbnail_url": None,
                "published_at": pub_date_str,   # String (Date format)
                "created_at": pub_date_str      # String (Date format)
            }
        }
        yield doc

# ==========================================
# 3. ì‹¤í–‰ (Execution)
# ==========================================
try:
    # ì¸ë±ìŠ¤ ìƒì„±/ì‚­ì œ ë¡œì§ì€ ì œê±°í–ˆìŠµë‹ˆë‹¤. (Spring Boot ì•± ì‹¤í–‰ ì‹œ ìë™ ìƒì„±ë¨ì„ ì „ì œ)
    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” 'contents' ì¸ë±ìŠ¤ì— ë°ì´í„°ë§Œ ë°€ì–´ë„£ìŠµë‹ˆë‹¤.
    
    success, failed = helpers.bulk(es, generate_docs(), chunk_size=BATCH_SIZE)
    print(f"âœ… ì™„ë£Œ! ì„±ê³µ: {success}, ì‹¤íŒ¨: {failed}")

except Exception as e:
    print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
